# Scrape

Несколько скриптов для парсинга сайтов. В основном используется BeautifulSoap и requests, а также немного регексп для корректного изъятия информации.


## [forklog.py](https://github.com/z00k0/scrape/blob/main/forklog.py)

На сайте https://forklog.com/ с 14 по 26 декабря проводился конкурс. Раз в сутки в одной из новостей пряталось слово в виде **[1 - word]**. Чтобы не искать слова вручную был написан этот скрипт. Скрипт парсил новости. Найденные слова складывал в файл *words.json*.


## [ufavodokanal.py](https://github.com/z00k0/scrape/blob/main/ufavodokanal.py "ufavodokanal.py")

Скрипт для сбора информации по задолженности в личном кабинете [УфаВодоКанал](https://www.ufavodokanal.ru/personal/). Выводит:
- Номер счета
- Адрес
- Задолженность

Для работы скрипта необходим логин и пароль от личного кабинета. Используется модуль *requests.Session()*


## [scrape_bashrts.py](https://github.com/z00k0/scrape/blob/main/scrape_bashrts.py "scrape_bashrts.py")

Скрипт для сбора информации по задолженности в личном кабинете [БашРТС](https://lkpe.bashrts.bgkrb.ru/Account/Login?ReturnUrl=%2F). Выводит:
- Имя
- Номер счета
- Адрес
- Сумма к оплате
- Номер счетчика
- Показания

Для работы скрипта необходим логин и пароль от личного кабинета. Используется модуль *requests.Session()* + для корректной работы понадобилось считывать из тела страницы и сохранять специальный токен.

## [tbx_parser.py](https://github.com/z00k0/scrape/blob/main/tbx_parser.py)

Небольшой скрипт для парсинга *.tbx файлов. Положить в папку с нужными файлами. При запуске скрипт парсит все *.tbx файлы в папке и сохраняет в Exel под именами file_name.tbx.xlsx